üëâ**Briefly about the essence**: showcase how to extract organic, cite results and store it to CSV file using `pandas` or MySQL Lite
database using Python `sqlite3` and `serpapi` library.

üî®**What is required**: Understanding of loops, data structures, exception handling and basic knowledge of `CSS` selectors. `serpapi`
, `pandas`, `sqlite3` libraries.

‚è±Ô∏è**How long will it take**: ~15-30 minutes.

___

- <a href="#intro">Intro</a>
- <a href="#what_will_be_scraped">What will be scraped</a>
- <a href="#prerequisites">Prerequisites</a>
- <a href="#process">Process</a>
- <a href="#full_code">Full Code</a>
- <a href="#links">Links</a>
- <a href="#outro">Outro</a>

___

<h2 id="intro">Intro</h2>

This tutorial blog post will show and guide you through the process of scraping _ with Python in an easy step-by-step explanation
using `beautifulsoup`, `requests`, `lxml` libraries.

<h2 id="what_will_be_scraped">What will be scraped</h2>

Text describing what will be scraped.

![img](http://visual-storytelling.ru/pictures/compose-01@2x.jpg)

<h2 id="prerequisites">Prerequisites</h2>

**Basic knowledge scraping with CSS selectors**

If you haven't scraped with CSS selectors, there's a dedicated blog post of mine
about [how to use CSS selectors when web-scraping](https://serpapi.com/blog/web-scraping-with-css-selectors-using-python/) that covers what
it is, pros and cons, and why they're matter from a web-scraping perspective.

CSS selectors declare which part of the markup a style applies to thus allowing to extract data from matching tags and attributes.

**Separate virtual environment**

If you didn't work with a virtual environment before, have a look at the
dedicated [Python virtual environments tutorial using Virtualenv and Poetry](https://serpapi.com/blog/python-virtual-environments-using-virtualenv-and-poetry/)
blog post of mine to get familiar.

In short, it's a thing that creates an independent set of installed libraries including different Python versions that can coexist with each
other at the same system thus preventing libraries or Python version conflicts.

üìåNote: this is not a strict requirement for this blog post.

**Install libraries**:

```lang-none
pip install requests
pip install lxml 
pip install beautifulsoup4
```

**Reduce the chance of being blocked**

There's a chance that a request might be blocked. Have a look
at [how to reduce the chance of being blocked while web-scraping](https://serpapi.com/blog/how-to-reduce-chance-of-being-blocked-while-web/)
, there are eleven methods to bypass blocks from most websites and some of them will be covered in this blog post.

___

<h2 id="process">Process</h2>

If you don't need an explanation:

- <a href="#full_code">jump to the full code section</a>,
- [grab the full code from the GitHub repository](Link),
- [try it in the online IDE]().

Extraction part..



___

<h2 id="full_code">Full Code</h2>

```python
# code
```

___


Alternatively, you can achieve the same by using SerpApi. SerpApi is a paid API with a free plan.

The difference is that there's no need to create the parser from scratch and maintain it overtime if something is broken.

... other differences.

```python
# code
```

___

<h2 id="links">Links</h2>

- [Code in the online IDE]()
- [API]()

___

<h2 id="outro">Outro</h2>

If you have anything to share, any questions, suggestions, or something that isn't working correctly, feel free to drop a comment in the
comment section or reach out via Twitter at [@dimitryzub](https://twitter.com/DimitryZub), or [@serp_api](https://twitter.com/serp_api).

Yours, Dmitriy, and the rest of SerpApi Team.

<h2 id="outro">What's next</h2>

With this data it should be possible to do a research or build a graph for certain discipline. A great additional feature would be to run
script every week, month to get additional data.

If your goal is to extract data without the need to write a parser from scratch, figure out how to bypass blocks from search engines, how to
scale it or how to extract data from JavaScript - [have a try SerpApi](https://serpapi.com/)
or [contact SerpApi](https://serpapi.com/#contact).

___

<p style="text-align: center;">Join us on <a href="https://www.reddit.com/r/SerpApi/">Reddit</a> | <a href="https://twitter.com/serp_api">Twitter</a> | <a href="https://www.youtube.com/channel/UCUgIHlYBOD3yA3yDIRhg_mg">YouTube</a></p>

<p style="text-align: center;">Add a  <a href="https://forum.serpapi.com/feature-requests">Feature Request</a>üí´ or a <a href="https://forum.serpapi.com/bugs">Bug</a>üêû</p>

